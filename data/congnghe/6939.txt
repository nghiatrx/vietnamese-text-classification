Giúp mạng thần kinh nhân tạo giải quyết được đến 8 công việc khác nhau, Google đang tiến một bước đột phá trong công nghệ AI Mạng thần kinh nhân tạo mới MultiModel của Google hứa hẹn sẽ khiến AI cuối cùng cũng có thể làm tốt nhiều công việc khác nhau.Các hệ thống học sâu (deep-learning) có xu hướng trở thành một kì quan với chỉ một bài tủ: Chúng sẽ cực kì xuất sắc ở bất cứ tác vụ nào mà chúng được huấn luyện để làm, nhưng sẽ đồng thời khá tệ hại ở mọi tác vụ khác. Tuy nhiên giờ đây, một mạng thần kinh nhân tạo mới từ Google hứa hẹn sẽ khiến AI cuối cùng cũng có thể làm tốt nhiều công việc khác nhau. Hầu hết các hệ thống học sâu được xây dựng nên để giải quyết một tổ hợp các vấn đề cụ thể, như nhận diện động vật từ hình ảnh hay dịch giữa các ngôn ngữ với nhau. Nhưng nếu bạn lấy một thuật toán nhận diện hình ảnh chẳng hạn, và rồi tái huấn luyện để nó thực hiện một nhiệm vụ hoàn toàn khác, chẳng hạn như nhận diện giọng nói, nó thường sẽ trở nên tệ hại khi trở lại với phần việc nguyên bản của mình. Con người chúng ta dường như không bị vấn đề này. Chúng ta một cách tự nhiên sử dụng kiến thức của mình để giải quyết các tác vụ mới mà hiếm khi quên đi các kĩ năng sẵn có của mình. Mạng thần kinh nhân tạo của Google đã tạo nên một bước ngoặt nho nhỏ tới khả năng đó của con người, bằng việc học một cách đồng thời giải quyết một loạt các vấn đề mà không chuyên hóa vào bất cứ vấn đề nào cả. Mạng thần kinh nhân tạo từ Google Brain - một trong những đội nghiên cứu học sâu của gã khổng lồ về tìm kiếm - đã học được cách thực hiện đến tận...8 tác vụ cùng lúc, bao gồm nhận diện ảnh và giọng nói, cùng với việc phân tích câu và dịch. Hệ thống này, được gọi là MultiModel, được tạo nên bởi một mạng thần kinh trung tâm vây quanh bởi các mạng thứ cấp được chuyên hóa trong các tác vụ cụ thể có liên quan đến văn bản, hình ảnh và âm thanh.  Hoạt động ổn định Mặc dù MultiModel không hề phá vỡ bất cứ kỉ lục nào cho số tác vụ mà nó có thể cáng đáng, tuy nhiên hiệu suất của nó lại khá cao. Với độ chính xác cỡ 88,6%, khả năng nhận diện hình ảnh của nó chỉ kém 9% so với các thuật toán chuyên hóa tốt nhất - và đuổi kịp khả năng của các thuật toán tốt nhất đã sử dụng trong 5 năm trở lại đây. Hệ thống cũng cho thấy các lợi ích khác. Các hệ thống học sâu thường cần được luyện tập với một lượng lớn dữ liệu để hoàn thành tác vụ tốt. Nhưng MultiModel dường như nảy ra một ý tưởng rất hay ho để vượt qua rào cản này, Ví dụ như khả năng của mạng trong việc phân tích ngữ pháp các câu được cải thiện rõ rệt khi nó được tập luyện trên một nền tảng dữ liệu...hình ảnh, mặc dù dạng dữ liệu này chẳng liên quan gì đến phân tích câu cả. Sebastian Ruder ở Trung tâm nghiên cứu Dữ liệu Phân tích ở Dublin, Ireland, cực kì ấn tượng với phương hướng tiếp cận của Google. Nếu một mạng thần kinh nhân tạo có thể sử dụng chính kiến thức của nó để giúp nó giải quyết các vấn đề hoàn toàn khác, nó hoàn toàn có thể cải thiện khả năng của mình với những vấn đề rất khó học do thiếu dữ liệu hữu ích. "Đây là chìa khóa để giúp chúng ta tiến gần hơn đến trí thông minh phổ quát nhân tạo," ông nói. Giải quyết vấn đề khó khăn này có thể chính là một bước đột phá trong hành trình hướng đến trí tuệ nhân tạo của loài người ?  Google đã phát hành các dòng code của MultiModel vốn là một phần của dự án mã nguồn mở TensorFlow, giúp cho các kĩ sư có cơ hội thử nghiệm với mạng thần kinh nhân tạo và đưa nó vào thử nghiệm. Tuy thế sự phức tạp của mạng này có thể sẽ gây khó khăn cho các nhà nghiên cứu trong việc tìm ra lý do đứng đằng sau các kĩ năng của nó. Tham khảo : NewScientist